#!/bin/bash

# Script de setup para GPT Chat Local
# Compatible com Linux e macOS

set -e

echo "ü§ñ GPT Chat Local - Setup Autom√°tico"
echo "======================================"

# Verificar Node.js
echo "üìã Verificando pr√©-requisitos..."
if ! command -v node &> /dev/null; then
    echo "‚ùå Node.js n√£o encontrado!"
    echo "   Por favor instale Node.js 18+ em https://nodejs.org/"
    exit 1
fi

NODE_VERSION=$(node --version | cut -d 'v' -f2 | cut -d '.' -f1)
if [ "$NODE_VERSION" -lt "18" ]; then
    echo "‚ùå Node.js muito antigo (v$NODE_VERSION)!"
    echo "   Por favor atualize para Node.js 18+ em https://nodejs.org/"
    exit 1
fi

echo "‚úÖ Node.js $(node --version) encontrado"

# Verificar npm
if ! command -v npm &> /dev/null; then
    echo "‚ùå npm n√£o encontrado!"
    exit 1
fi

echo "‚úÖ npm $(npm --version) encontrado"

# Instalar depend√™ncias
echo ""
echo "üì¶ Instalando depend√™ncias..."
npm install

# Configurar .env
echo ""
echo "‚öôÔ∏è  Configurando vari√°veis de ambiente..."
if [ ! -f ".env" ]; then
    cp .env.example .env
    echo "‚úÖ Arquivo .env criado"
else
    echo "‚ÑπÔ∏è  Arquivo .env j√° existe"
fi

# Setup do banco de dados
echo ""
echo "üóÑÔ∏è  Configurando banco de dados SQLite..."
npx prisma generate
npx prisma migrate dev --name init

# Verificar Ollama
echo ""
echo "üîç Verificando Ollama..."
if ! command -v ollama &> /dev/null; then
    echo "‚ö†Ô∏è  Ollama n√£o encontrado!"
    echo ""
    echo "   Para instalar o Ollama:"
    echo "   ‚Ä¢ macOS: brew install ollama"
    echo "   ‚Ä¢ Linux: curl -fsSL https://ollama.ai/install.sh | sh"
    echo "   ‚Ä¢ Windows: Baixe em https://ollama.ai/"
    echo ""
    echo "   Ap√≥s instalar, execute:"
    echo "   ‚Ä¢ ollama serve"
    echo "   ‚Ä¢ ollama pull llama3:latest"
    OLLAMA_MISSING=true
else
    echo "‚úÖ Ollama encontrado"
    
    # Verificar se o servi√ßo est√° rodando
    if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
        echo "‚úÖ Servi√ßo Ollama est√° rodando"
        
        # Listar modelos
        MODELS=$(ollama list | grep -v "NAME" | wc -l)
        if [ "$MODELS" -gt "0" ]; then
            echo "‚úÖ Modelos encontrados:"
            ollama list
        else
            echo "‚ö†Ô∏è  Nenhum modelo encontrado!"
            echo "   Execute: ollama pull llama3:latest"
            OLLAMA_NO_MODELS=true
        fi
    else
        echo "‚ö†Ô∏è  Servi√ßo Ollama n√£o est√° rodando!"
        echo "   Execute: ollama serve"
        OLLAMA_NOT_RUNNING=true
    fi
fi

# Resultado final
echo ""
echo "üéâ Setup conclu√≠do!"
echo "=================="

if [ -z "$OLLAMA_MISSING" ] && [ -z "$OLLAMA_NOT_RUNNING" ] && [ -z "$OLLAMA_NO_MODELS" ]; then
    echo "‚úÖ Tudo pronto! Execute: npm run dev"
else
    echo "‚ö†Ô∏è  A√ß√µes necess√°rias:"
    if [ "$OLLAMA_MISSING" = true ]; then
        echo "   1. Instale o Ollama"
    fi
    if [ "$OLLAMA_NOT_RUNNING" = true ]; then
        echo "   2. Inicie: ollama serve"
    fi
    if [ "$OLLAMA_NO_MODELS" = true ]; then
        echo "   3. Baixe um modelo: ollama pull llama3:latest"
    fi
    echo "   4. Execute: npm run dev"
fi

echo ""
echo "üìö Para mais informa√ß√µes, consulte o README.md"
